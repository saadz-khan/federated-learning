{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PySyft Basics & Federated Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY/lP1ZttPrFSZQcEL7jnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadz-khan/federated-learning/blob/master/PySyft_Basics_%26_Federated_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Syft Basics"
      ],
      "metadata": {
        "id": "DGw5-jmbkS5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking Versions"
      ],
      "metadata": {
        "id": "A-TvlTBMZa-e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bNwQmikYWXb",
        "outputId": "4b97694c-e219-484d-e699-7d3825af745a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4.0\n",
            "3.7.13 (default, Apr 24 2022, 01:04:09) \n",
            "[GCC 7.5.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install & Importing Dependencies "
      ],
      "metadata": {
        "id": "UFZXuuLfaFkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install syft==0.2.9"
      ],
      "metadata": {
        "id": "GRKye8a6Z-wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import syft as sy\n",
        "hook = sy.TorchHook(torch)"
      ],
      "metadata": {
        "id": "eBFW-PVuaJLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fun with Jake"
      ],
      "metadata": {
        "id": "fkxN9jo7bgZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Jake"
      ],
      "metadata": {
        "id": "6mvdAUUQbmqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jake = sy.VirtualWorker(hook, id=\"jake\")\n",
        "print(\"Jake has: \" + str(jake._objects))"
      ],
      "metadata": {
        "id": "xXEukTeRbifC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending Data to Jake"
      ],
      "metadata": {
        "id": "KO2YjGobboDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1, 2, 3, 4, 5])\n",
        "x = x.send(jake)                          # x is a pointer to tensor sent to Jake\n",
        "print(\"x: \" + str(x))\n",
        "print(\"Jake has: \" + str(jake._objects))"
      ],
      "metadata": {
        "id": "z4crwxMpbqUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Jake's Data"
      ],
      "metadata": {
        "id": "gjdcnAVVbtrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.get()\n",
        "print(\"x: \" + str(x))\n",
        "print(\"Jake has: \" + str(jake._objects))"
      ],
      "metadata": {
        "id": "0yRMNFt-bwWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Say Hi to John"
      ],
      "metadata": {
        "id": "xlKjH1oGctwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending Data to John"
      ],
      "metadata": {
        "id": "ptBu7Cv5dAUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "john = sy.VirtualWorker(hook, id=\"john\")\n",
        "x = x.send(jake)                          # x is a pointer to tensor sent to Jake\n",
        "x = x.send(john)                          # John now has Pointer to Jake's Data\n",
        "print(\"x: \" + str(x))\n",
        "print(\"John has: \" + str(john._objects))\n",
        "print(\"Jake has: \" + str(jake._objects))"
      ],
      "metadata": {
        "id": "p3qiN4_xcvl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning Up Data"
      ],
      "metadata": {
        "id": "xar5xCZ1c-UF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jake.clear_objects()\n",
        "john.clear_objects()\n",
        "print(\"Jake has: \" + str(jake._objects))\n",
        "print(\"John has: \" + str(john._objects))"
      ],
      "metadata": {
        "id": "77aCm9S2dCP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving Data from Jake to John"
      ],
      "metadata": {
        "id": "jqJT3nrJdcQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([6, 7, 8, 9, 10]).send(jake)\n",
        "y = y.move(john)\n",
        "print(y)\n",
        "print(\"Jake has: \" + str(jake._objects))\n",
        "print(\"John has: \" + str(john._objects))"
      ],
      "metadata": {
        "id": "HV7wauAQdbhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additive Secret Sharing"
      ],
      "metadata": {
        "id": "_KmUViVyfk6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encryption"
      ],
      "metadata": {
        "id": "2ktlrKKcfypN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# setting Q to a very large prime number\n",
        "Q = 23740629843760239486723\n",
        "\n",
        "\n",
        "def encrypt(x, n_share=3):\n",
        "    r\"\"\"Returns a tuple containg n_share number of shares\n",
        "    obtained after encrypting the value x.\"\"\"\n",
        "\n",
        "    shares = list()\n",
        "    for i in range(n_share - 1):\n",
        "        shares.append(random.randint(0, Q))\n",
        "    shares.append(Q - (sum(shares) % Q) + x)\n",
        "    return tuple(shares)\n",
        "\n",
        "\n",
        "print(\"Shares: \" + str(encrypt(3)))"
      ],
      "metadata": {
        "id": "IqRkUE5tfpQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decryption"
      ],
      "metadata": {
        "id": "26Yblciqf0BZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt(shares):\n",
        "    r\"\"\"Returns a value obtained by decrypting the shares.\"\"\"\n",
        "\n",
        "    return sum(shares) % Q\n",
        "\n",
        "\n",
        "print(\"Value after decrypting: \" + str(decrypt(encrypt(3))))"
      ],
      "metadata": {
        "id": "eB5bcVGYf06f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Homomorphic Encryption"
      ],
      "metadata": {
        "id": "JVi-hZP7hDzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a, b):\n",
        "    r\"\"\"Returns a value obtained by adding the shares a and b.\"\"\"\n",
        "\n",
        "    c = list()\n",
        "    for i in range(len(a)):\n",
        "        c.append((a[i] + b[i]) % Q)\n",
        "    return tuple(c)\n",
        "\n",
        "\n",
        "x, y = 6, 8\n",
        "a = encrypt(x)\n",
        "b = encrypt(y)\n",
        "c = add(a, b)\n",
        "print(\"Shares encrypting x: \" + str(a))\n",
        "print(\"Shares encrypting y: \" + str(b))\n",
        "print(\"Sum of shares: \" + str(c))\n",
        "print(\"Sum of original values (x + y): \" + str(decrypt(c)))"
      ],
      "metadata": {
        "id": "0D-7xlxPhGGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Secret Sharing Using Pysyft"
      ],
      "metadata": {
        "id": "-7BoXQtnhim-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jake = sy.VirtualWorker(hook, id=\"jake\")\n",
        "john = sy.VirtualWorker(hook, id=\"john\")\n",
        "secure_worker = sy.VirtualWorker(hook, id=\"secure_worker\")\n",
        "\n",
        "jake.add_workers([john, secure_worker])\n",
        "john.add_workers([jake, secure_worker])\n",
        "secure_worker.add_workers([jake, john])\n",
        "\n",
        "print(\"Jake has: \" + str(jake._objects))\n",
        "print(\"John has: \" + str(john._objects))\n",
        "print(\"Secure_worker has: \" + str(secure_worker._objects))"
      ],
      "metadata": {
        "id": "fLPbI8Cmhlxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([6])\n",
        "x = x.share(jake, john, secure_worker)\n",
        "print(\"x: \" + str(x))\n",
        "\n",
        "print(\"Jake has: \" + str(jake._objects))\n",
        "print(\"John has: \" + str(john._objects))\n",
        "print(\"Secure_worker has: \" + str(secure_worker._objects))"
      ],
      "metadata": {
        "id": "Iv090CqIh4rL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.tensor([8])\n",
        "y = y.share(jake, john, secure_worker)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "-RBi8i8QjlgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "id": "G1hcsg2SjtlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = z.get()\n",
        "print(z)"
      ],
      "metadata": {
        "id": "wwO88aUMkDcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Federated Learning"
      ],
      "metadata": {
        "id": "y118ue1gkV6o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Dependencies"
      ],
      "metadata": {
        "id": "W3MFllrVkYNj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "N_uhjV6YkXPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Datasets"
      ],
      "metadata": {
        "id": "3cQXCFK4keV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, ), (0.5, )),\n",
        "])\n",
        "\n",
        "train_set = datasets.MNIST(\n",
        "    \"~/.pytorch/MNIST_data/\", train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(\n",
        "    \"~/.pytorch/MNIST_data/\", train=False, download=True, transform=transform)\n",
        "\n",
        "federated_train_loader = sy.FederatedDataLoader(\n",
        "    train_set.federate((jake, john)), batch_size=64, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "WgleOlq8kf3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Model"
      ],
      "metadata": {
        "id": "2wJV_uTonneI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "model = Model()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "BUaZ13nbnoqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "etTVLhgppCYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0, 5):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(federated_train_loader):\n",
        "        # send the model to the client device where the data is present\n",
        "        model.send(data.location)\n",
        "        # training the model\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # get back the improved model\n",
        "        model.get()\n",
        "        if batch_idx % 100 == 0:\n",
        "            # get back the loss\n",
        "            loss = loss.get()\n",
        "            print('Epoch: {:2d} [{:5d}/{:5d} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch+1,\n",
        "                batch_idx * 64,\n",
        "                len(federated_train_loader) * 64,\n",
        "                100. * batch_idx / len(federated_train_loader),\n",
        "                loss.item()))"
      ],
      "metadata": {
        "id": "Y7a6c17TpD8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the Model"
      ],
      "metadata": {
        "id": "Knf1nhOR0PUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "        output = model(data)\n",
        "        test_loss += F.nll_loss(\n",
        "            output, target, reduction='sum').item()\n",
        "        # get the index of the max log-probability\n",
        "        pred = output.argmax(1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "test_loss /= len(test_loader.dataset)\n",
        "\n",
        "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss,\n",
        "    correct,\n",
        "    len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "8WvhkP7q0SaB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}